{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "583f7f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = r\"E:\\CHANDRU\\chand proj\\MOUD\\VideoReviews\\transcriptions\\*.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5c79738",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b31dd82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "for f in glob.glob(train_path):\n",
    "    df = df.append(pd.read_csv(f,sep=';'),ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8d20277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#starttime</th>\n",
       "      <th>#endtime</th>\n",
       "      <th>transcription</th>\n",
       "      <th>sentimentAnnotations</th>\n",
       "      <th>Speech</th>\n",
       "      <th>speech</th>\n",
       "      <th>sentimentAnnotation</th>\n",
       "      <th>sentimentannotations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000</td>\n",
       "      <td>3.642</td>\n",
       "      <td>yo habia visto resenas que decian que picaba c...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.642</td>\n",
       "      <td>9.552</td>\n",
       "      <td>y la verdad es que si la use una vez y t- y te...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.552</td>\n",
       "      <td>14.197</td>\n",
       "      <td>y dije no: puede ser posible tanto la deseaba ...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.197</td>\n",
       "      <td>20.545</td>\n",
       "      <td>esta tambien tira un poquito de pelo pero haga...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.545</td>\n",
       "      <td>23.275</td>\n",
       "      <td>pero igual con las lavadas se ha dejado de tir...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   #starttime  #endtime                                      transcription  \\\n",
       "0       0.000     3.642  yo habia visto resenas que decian que picaba c...   \n",
       "1       3.642     9.552  y la verdad es que si la use una vez y t- y te...   \n",
       "2       9.552    14.197  y dije no: puede ser posible tanto la deseaba ...   \n",
       "3      14.197    20.545  esta tambien tira un poquito de pelo pero haga...   \n",
       "4      20.545    23.275  pero igual con las lavadas se ha dejado de tir...   \n",
       "\n",
       "   sentimentAnnotations Speech speech  sentimentAnnotation  \\\n",
       "0                  -1.0    NaN    NaN                  NaN   \n",
       "1                  -1.0    NaN    NaN                  NaN   \n",
       "2                  -1.0    NaN    NaN                  NaN   \n",
       "3                  -1.0    NaN    NaN                  NaN   \n",
       "4                   1.0    NaN    NaN                  NaN   \n",
       "\n",
       "   sentimentannotations  \n",
       "0                   NaN  \n",
       "1                   NaN  \n",
       "2                   NaN  \n",
       "3                   NaN  \n",
       "4                   NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "891c735d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# funcion to append all utterances to dataframe\n",
    "def create_data_df(df_name,data_path):\n",
    "    \n",
    "    # Creating dataframe of entire transcriptions\n",
    "    for f in glob.glob(data_path):\n",
    "        df_name = df_name.append(pd.read_csv(f,sep=';'),ignore_index=True)\n",
    "    \n",
    "    # combine multiple speech, annotation columns to one and drop rest of columns\n",
    "    if 'Speech' not in df_name.columns:\n",
    "        df_name['Speech'] = ''    \n",
    "    if 'speech' in df_name.columns:\n",
    "        df_name['Speech'] = df_name[['Speech','speech']].fillna('').sum(axis=1)   \n",
    "    if 'transcription' in df_name.columns:\n",
    "        df_name['Speech'] = df_name[['Speech','transcription']].fillna('').sum(axis=1)\n",
    "    \n",
    "    if 'sentimentAnnotation' not in df_name.columns:\n",
    "        df_name['sentimentAnnotation'] = 0    \n",
    "    if 'sentimentAnnotations' in df_name.columns:\n",
    "        df_name['sentimentAnnotation'] = df_name[['sentimentAnnotation','sentimentAnnotations']].fillna(0).sum(axis=1)\n",
    "    if 'sentimentannotations' in df_name.columns:\n",
    "        df_name['sentimentAnnotation'] = df_name[['sentimentAnnotation','sentimentannotations']].fillna(0).sum(axis=1)\n",
    "    \n",
    "    # Remove neutral annotations\n",
    "    df_name = df_name.query('sentimentAnnotation != 0')\n",
    "    \n",
    "    df_name = df_name[['Speech','sentimentAnnotation']].reset_index(drop=True)  \n",
    "    return df_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c74309f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Speech</th>\n",
       "      <th>sentimentAnnotation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yo habia visto resenas que decian que picaba c...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>y la verdad es que si la use una vez y t- y te...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>y dije no: puede ser posible tanto la deseaba ...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>esta tambien tira un poquito de pelo pero haga...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pero igual con las lavadas se ha dejado de tir...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Speech  sentimentAnnotation\n",
       "0  yo habia visto resenas que decian que picaba c...                 -1.0\n",
       "1  y la verdad es que si la use una vez y t- y te...                 -1.0\n",
       "2  y dije no: puede ser posible tanto la deseaba ...                 -1.0\n",
       "3  esta tambien tira un poquito de pelo pero haga...                 -1.0\n",
       "4  pero igual con las lavadas se ha dejado de tir...                  1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df = create_data_df(df,train_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d69a31a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(450, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(450, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eebee050",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f6354b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Speech</th>\n",
       "      <th>sentimentAnnotation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yo habia visto resenas que decian que picaba c...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>la verdad es que si la use una vez te arde asi...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dije puede ser posible tanto la deseaba arde l...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>esta tambien tira un poquito de pelo pero haga...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pero igual con las lavadas se ha dejado de tirar</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Speech  sentimentAnnotation\n",
       "0  yo habia visto resenas que decian que picaba c...                 -1.0\n",
       "1  la verdad es que si la use una vez te arde asi...                 -1.0\n",
       "2  dije puede ser posible tanto la deseaba arde l...                 -1.0\n",
       "3  esta tambien tira un poquito de pelo pero haga...                 -1.0\n",
       "4   pero igual con las lavadas se ha dejado de tirar                  1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "# resuable function to convert raw speech to preprocessed\n",
    "def utterance_to_words(raw_utterance):\n",
    "    # 1. Removing HTML elements from text\n",
    "    utterance_text = BeautifulSoup(raw_utterance,\"lxml\").get_text()\n",
    "    # TRANSLATION\n",
    "    #translated_utterance = translator.translate(utterance_text,from_lang=\"spanish\",to_lang = 'english')\n",
    "    # 2. Keeping only letters\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", utterance_text) \n",
    "    # 3. Converting to lower case and splitting into individual words\n",
    "    lowercase_words = letters_only.lower().split()\n",
    "    # 4. converting the stop words to a set to help faster execution\n",
    "    spanish_stops = set(stopwords.words(\"english\"))\n",
    "    # 5. Removing stop words from the text\n",
    "    meaningful_words = [w for w in lowercase_words if not w in spanish_stops]\n",
    "    # 6. Join the words back into one string separated by space, and return the result.\n",
    "    return( \" \".join( meaningful_words ))\n",
    "    \n",
    "# applying the function to the speech columns\n",
    "df['Speech'] = df['Speech'].apply(lambda x: utterance_to_words(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99c606db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(text):\n",
    "    from googletrans import Translator\n",
    "    translator = Translator()\n",
    "    translated_text = translator.translate(text, dest='en').text\n",
    "    return translated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af9ca80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_tags=[]\n",
    "for i in df['Speech']:\n",
    "    s=translate(i)\n",
    "    t_tags.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a73385d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Review']=t_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35b1ce99",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = df[['Review']],df[['sentimentAnnotation']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1f6b137c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Review\n",
      "0    I had seen penetrates that they said when you ...\n",
      "1    The truth is that if I use it once you burns y...\n",
      "2    I said it can be possible so much I wanted to ...\n",
      "3    This also throws a little hair but they realiz...\n",
      "4    But the same with the washes has stopped throwing\n",
      "..                                                 ...\n",
      "445  Already in other LIs in other videos already t...\n",
      "446  If they are curious if they have caught their ...\n",
      "447  Be the first time that I saw them were so parents\n",
      "448  Here I am five books after being super fan and...\n",
      "449  sometimes he reads this book I felt like Cassa...\n",
      "\n",
      "[450 rows x 1 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentimentAnnotation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>450 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sentimentAnnotation\n",
       "0                   -1.0\n",
       "1                   -1.0\n",
       "2                   -1.0\n",
       "3                   -1.0\n",
       "4                    1.0\n",
       "..                   ...\n",
       "445                  1.0\n",
       "446                  1.0\n",
       "447                 -1.0\n",
       "448                  1.0\n",
       "449                  1.0\n",
       "\n",
       "[450 rows x 1 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5665a7d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: (360, 1)\n",
      "y_train: (360, 1)\n",
      "x_test: (90, 1)\n",
      "y_test: (90, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(X,Y,test_size=0.2,random_state=41)\n",
    "print('x_train:',x_train.shape)\n",
    "print('y_train:',y_train.shape)\n",
    "print('x_test:',x_test.shape)\n",
    "print('y_test:',y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e5071df9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<360x1011 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 4128 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tf_vector = TfidfVectorizer()\n",
    "X_train_t = tf_vector.fit_transform(x_train['Review'])\n",
    "X_train_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0946feae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# def create_tfidf_vectors(train_reviews):\n",
    "#     tf_vector = TfidfVectorizer()\n",
    "#     tfidf_vectors = tf_vector.fit_transform(train_reviews)\n",
    "#     return tfidf_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4a829477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<90x1011 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 925 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_tf = tf_vector.transform(x_test['Review'])\n",
    "X_test_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a6711dec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "models = LogisticRegression()\n",
    "models.fit(X_train_t,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6f351747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_accuracy: 0.9138888888888889\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "l_train_score = models.predict(X_train_t)\n",
    "l_train_accuracy = accuracy_score(l_train_score,y_train)\n",
    "print('train_accuracy:',l_train_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1e0dde87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acccuracy: 0.7\n"
     ]
    }
   ],
   "source": [
    "l_test_score = models.predict(X_test_tf)\n",
    "l_test_accuracy = accuracy_score(l_test_score,y_test) \n",
    "print('test_acccuracy:',l_test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4affd871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No. of test samples :  90\n",
      "\n",
      " Confustion Matrix : \n",
      " [[43  6]\n",
      " [21 20]]\n",
      "\n",
      "Perfomance measures are: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.67      0.88      0.76        49\n",
      "         1.0       0.77      0.49      0.60        41\n",
      "\n",
      "    accuracy                           0.70        90\n",
      "   macro avg       0.72      0.68      0.68        90\n",
      "weighted avg       0.72      0.70      0.69        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,accuracy_score, confusion_matrix\n",
    "cmx_1=confusion_matrix(y_test,l_test_score)\n",
    "print(\"\\nNo. of test samples : \",len(x_test))\n",
    "print(\"\\n Confustion Matrix : \\n\",cmx_1)\n",
    "print(\"\\nPerfomance measures are: \\n\",classification_report(y_test, l_test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "170e5b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "support = svm.SVC()\n",
    "support.fit(X_train_t,y_train)\n",
    "train_score_1 = support.predict(X_train_t)\n",
    "train_accuracy_1 = accuracy_score(train_score_1,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b06e0ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score_1 = support.predict(X_test_tf)\n",
    "test_accuracy_1 = accuracy_score(test_score_1,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1c1c5896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No. of test samples :  90\n",
      "\n",
      " Confustion Matrix : \n",
      " [[44 19]\n",
      " [ 5 22]]\n",
      "\n",
      "Perfomance measures are: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.90      0.70      0.79        63\n",
      "         1.0       0.54      0.81      0.65        27\n",
      "\n",
      "    accuracy                           0.73        90\n",
      "   macro avg       0.72      0.76      0.72        90\n",
      "weighted avg       0.79      0.73      0.74        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cmx_2=confusion_matrix(test_score_1,y_test)\n",
    "print(\"\\nNo. of test samples : \",len(x_test))\n",
    "print(\"\\n Confustion Matrix : \\n\",cmx_2)\n",
    "print(\"\\nPerfomance measures are: \\n\",classification_report(test_score_1,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "842c175c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "But the same with the washes has stopped throwing\n"
     ]
    }
   ],
   "source": [
    "dft = df.loc[4,'Review']\n",
    "print(dft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9eba5c8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.,  1.])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data={\"review\":[\"The truth is that if I use it once you burns you where you use it burns your eye\",\n",
    "                \"But the same with the washes has stopped throwing\"]}\n",
    "data=pd.DataFrame(data)\n",
    "new=tf_vector.transform(data['review'])\n",
    "\n",
    "pred=support.predict(new)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "409d7b99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1., -1.])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1={\"review\":[\"Go for it. Fabric is good. But have small doubt if it will gets shrink after washing. Overall it's good. Though the dupatta is shorter.\"\n",
    "                ,\"I want to returned it because of size issue but there is no option. Disappointed One person found this helpful\"]} \n",
    "data1=pd.DataFrame(data1)\n",
    "new=tf_vector.transform(data1['review'])\n",
    "\n",
    "pred1=support.predict(new)\n",
    "pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3c0ca357",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Save the model using pickle.dump()\n",
    "with open('support.pkl', 'wb') as file:\n",
    "    pickle.dump(support, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b9a03c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Save the model using pickle.dump()\n",
    "with open('tf_vector.pkl', 'wb') as file:\n",
    "    pickle.dump(tf_vector, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cd79a24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "89ae1d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model using pickle.load()\n",
    "with open('support.pkl', 'rb') as file:\n",
    "    support= pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e16252cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.,  1.])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data2={\"review\":[\"The truth is that if I use it once you burns you where you use it burns your eye\",\n",
    "                \"But the same with the washes has stopped throwing\"]}\n",
    "data2=pd.DataFrame(data2)\n",
    "new2=tf_vector.transform(data2['review'])\n",
    "\n",
    "pred2=support.predict(new2)\n",
    "pred2\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
